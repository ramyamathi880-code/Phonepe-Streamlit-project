{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd7b9cb-49ca-483f-9142-3c56a5be4e93",
   "metadata": {},
   "source": [
    "# Phonepe Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fdf03c-6ca3-40e5-8d3c-483ace189747",
   "metadata": {},
   "source": [
    "## Aggregated datas convert JSON into CSVs\n",
    "- data\n",
    "  - aggregated\n",
    "    - transaction\n",
    "    - insurance\n",
    "    - user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e74efd-d433-45b5-bc5b-2cc3c65d8888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV created for transaction at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\aggregated\\csv_outputs\\transaction_data.csv, total rows: 5034\n",
      "CSV created for user at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\aggregated\\csv_outputs\\user_data.csv, total rows: 7740\n",
      "CSV created for insurance at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\aggregated\\csv_outputs\\insurance_data.csv, total rows: 682\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base folder of Aggregated data\n",
    "base_folder = r\"C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\aggregated\"\n",
    "\n",
    "# Output folder for CSVs\n",
    "output_folder = os.path.join(base_folder, \"csv_outputs\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to process aggregated JSON\n",
    "def process_aggregated_json(category):\n",
    "    folder_path = os.path.join(base_folder, category, \"country\", \"india\", \"state\")\n",
    "    all_rows = []\n",
    "    \n",
    "    for state in os.listdir(folder_path):\n",
    "        state_path = os.path.join(folder_path, state)\n",
    "        if os.path.isdir(state_path):\n",
    "            for year in os.listdir(state_path):\n",
    "                year_path = os.path.join(state_path, year)\n",
    "                if os.path.isdir(year_path):\n",
    "                    for file in os.listdir(year_path):\n",
    "                        if file.endswith(\".json\"):\n",
    "                            file_path = os.path.join(year_path, file)\n",
    "                            with open(file_path, 'r') as f:\n",
    "                                data = json.load(f)\n",
    "                            \n",
    "                            # Aggregated Transaction & Insurance\n",
    "                            if category in [\"transaction\", \"insurance\"]:\n",
    "                                trans_data = data.get(\"data\", {}).get(\"transactionData\", [])\n",
    "                                for item in trans_data:\n",
    "                                    for instr in item.get(\"paymentInstruments\", []):\n",
    "                                        all_rows.append({\n",
    "                                            \"state\": state,\n",
    "                                            \"year\": year,\n",
    "                                            \"quarter\": file.replace(\".json\", \"\"),\n",
    "                                            \"name\": item.get(\"name\"),\n",
    "                                            \"type\": instr.get(\"type\"),\n",
    "                                            \"count\": instr.get(\"count\"),\n",
    "                                            \"amount\": instr.get(\"amount\"),\n",
    "                                            \"from\": data[\"data\"].get(\"from\"),\n",
    "                                            \"to\": data[\"data\"].get(\"to\")\n",
    "                                        })\n",
    "                            \n",
    "                            # Aggregated User\n",
    "                            elif category == \"user\":\n",
    "                                users_data = data.get(\"data\", {})\n",
    "                                aggregated = users_data.get(\"aggregated\", {})\n",
    "                                all_rows.append({\n",
    "                                    \"state\": state,\n",
    "                                    \"year\": year,\n",
    "                                    \"quarter\": file.replace(\".json\", \"\"),\n",
    "                                    \"registeredUsers\": aggregated.get(\"registeredUsers\"),\n",
    "                                    \"appOpens\": aggregated.get(\"appOpens\")\n",
    "                                })\n",
    "                                # Safely check if 'usersByDevice' exists\n",
    "                                users_by_device = users_data.get(\"usersByDevice\")\n",
    "                                if users_by_device:  # Only iterate if not None\n",
    "                                    for device in users_by_device:\n",
    "                                        all_rows.append({\n",
    "                                            \"state\": state,\n",
    "                                            \"year\": year,\n",
    "                                            \"quarter\": file.replace(\".json\", \"\"),\n",
    "                                            \"device_brand\": device.get(\"brand\"),\n",
    "                                            \"device_count\": device.get(\"count\"),\n",
    "                                            \"device_percentage\": device.get(\"percentage\")\n",
    "                                        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    output_csv = os.path.join(output_folder, f\"{category}_data.csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"CSV created for {category} at: {output_csv}, total rows: {len(df)}\")\n",
    "\n",
    "# Convert Aggregated datasets one by one\n",
    "categories = [\"transaction\", \"user\", \"insurance\"]\n",
    "for cat in categories:\n",
    "    process_aggregated_json(cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ed973-5b81-4aa9-9d49-389cda876696",
   "metadata": {},
   "source": [
    "## Map datas convert JSON into CSVs\n",
    "- data\n",
    "  - map\n",
    "    - transaction\n",
    "    - insurance\n",
    "    - user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f24a9b2-e41f-4ab7-a4e7-1919576637b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CSV created for transaction at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\map\\csv_outputs\\transaction_data.csv, total rows: 20604\n",
      " CSV created for user at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\map\\csv_outputs\\user_data.csv, total rows: 20608\n",
      " CSV created for insurance at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\map\\csv_outputs\\insurance_data.csv, total rows: 13876\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base folder of Map data\n",
    "base_folder = r\"C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\map\"\n",
    "\n",
    "# Output folder for CSVs\n",
    "output_folder = os.path.join(base_folder, \"csv_outputs\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to process Map JSON\n",
    "def process_map_json(category):\n",
    "    folder_path = os.path.join(base_folder, category, \"hover\", \"country\", \"india\", \"state\")\n",
    "    all_rows = []\n",
    "    \n",
    "    for state in os.listdir(folder_path):\n",
    "        state_path = os.path.join(folder_path, state)\n",
    "        if os.path.isdir(state_path):\n",
    "            for year in os.listdir(state_path):\n",
    "                year_path = os.path.join(state_path, year)\n",
    "                if os.path.isdir(year_path):\n",
    "                    for file in os.listdir(year_path):\n",
    "                        if file.endswith(\".json\"):\n",
    "                            file_path = os.path.join(year_path, file)\n",
    "                            with open(file_path, 'r') as f:\n",
    "                                data = json.load(f)\n",
    "                            \n",
    "                            year_val = year\n",
    "                            quarter = file.replace(\".json\", \"\")\n",
    "                            \n",
    "                            # hoverDataList (transaction/insurance)\n",
    "                            hover_list = data.get(\"data\", {}).get(\"hoverDataList\")\n",
    "                            if hover_list:\n",
    "                                for item in hover_list:\n",
    "                                    for metric in item.get(\"metric\", []):\n",
    "                                        all_rows.append({\n",
    "                                            \"state\": state,\n",
    "                                            \"year\": year_val,\n",
    "                                            \"quarter\": quarter,\n",
    "                                            \"name\": item.get(\"name\"),\n",
    "                                            \"type\": metric.get(\"type\"),\n",
    "                                            \"count\": metric.get(\"count\"),\n",
    "                                            \"amount\": metric.get(\"amount\")\n",
    "                                        })\n",
    "                            \n",
    "                            # hoverData dict (user)\n",
    "                            hover_dict = data.get(\"data\", {}).get(\"hoverData\")\n",
    "                            if hover_dict:\n",
    "                                for name, value in hover_dict.items():\n",
    "                                    all_rows.append({\n",
    "                                        \"state\": state,\n",
    "                                        \"year\": year_val,\n",
    "                                        \"quarter\": quarter,\n",
    "                                        \"name\": name,\n",
    "                                        \"registeredUsers\": value.get(\"registeredUsers\"),\n",
    "                                        \"appOpens\": value.get(\"appOpens\")\n",
    "                                    })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    output_csv = os.path.join(output_folder, f\"{category}_data.csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\" CSV created for {category} at: {output_csv}, total rows: {len(df)}\")\n",
    "\n",
    "# Map categories\n",
    "map_categories = [\"transaction\", \"user\", \"insurance\"]\n",
    "for cat in map_categories:\n",
    "    process_map_json(cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb148b-af4f-41fb-88c4-cab27b159b64",
   "metadata": {},
   "source": [
    "## Top datas convert JSON into CSVs\n",
    "- data\n",
    "  - Top\n",
    "    - transaction\n",
    "    - insurance\n",
    "    - user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12898146-cb16-40ca-8c5b-3bb6b22f696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CSV created for transaction at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\top\\csv_outputs\\transaction_data.csv, total rows: 18295\n",
      " CSV created for user at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\top\\csv_outputs\\user_data.csv, total rows: 18296\n",
      " CSV created for insurance at: C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\top\\csv_outputs\\insurance_data.csv, total rows: 12276\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base folder of Top data\n",
    "base_folder = r\"C:\\Users\\YAZHINI.YAZHNI-EM-SYS\\Downloads\\pulse-master\\phonepe_project\\data\\top\"\n",
    "\n",
    "# Output folder for CSVs\n",
    "output_folder = os.path.join(base_folder, \"csv_outputs\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to process Top JSON\n",
    "def process_top_json(category):\n",
    "    folder_path = os.path.join(base_folder, category, \"country\", \"india\", \"state\")\n",
    "    all_rows = []\n",
    "    \n",
    "    for state in os.listdir(folder_path):\n",
    "        state_path = os.path.join(folder_path, state)\n",
    "        if os.path.isdir(state_path):\n",
    "            for year in os.listdir(state_path):\n",
    "                year_path = os.path.join(state_path, year)\n",
    "                if os.path.isdir(year_path):\n",
    "                    for file in os.listdir(year_path):\n",
    "                        if file.endswith(\".json\"):\n",
    "                            file_path = os.path.join(year_path, file)\n",
    "                            with open(file_path, 'r') as f:\n",
    "                                data = json.load(f)\n",
    "                            \n",
    "                            year_val = year\n",
    "                            quarter = file.replace(\".json\", \"\")\n",
    "                            top_data = data.get(\"data\", {})\n",
    "\n",
    "                            # Safely iterate if list exists\n",
    "                            states_list = top_data.get(\"states\") or []\n",
    "                            districts_list = top_data.get(\"districts\") or []\n",
    "                            pincodes_list = top_data.get(\"pincodes\") or []\n",
    "\n",
    "                            # States\n",
    "                            for s in states_list:\n",
    "                                if \"metric\" in s:\n",
    "                                    all_rows.append({\n",
    "                                        \"level\": \"state\",\n",
    "                                        \"entity\": s.get(\"entityName\"),\n",
    "                                        \"type\": s[\"metric\"].get(\"type\"),\n",
    "                                        \"count\": s[\"metric\"].get(\"count\"),\n",
    "                                        \"amount\": s[\"metric\"].get(\"amount\"),\n",
    "                                        \"year\": year_val,\n",
    "                                        \"quarter\": quarter,\n",
    "                                        \"dataset\": category\n",
    "                                    })\n",
    "                                else:\n",
    "                                    all_rows.append({\n",
    "                                        \"level\": \"state\",\n",
    "                                        \"entity\": s.get(\"name\"),\n",
    "                                        \"registeredUsers\": s.get(\"registeredUsers\"),\n",
    "                                        \"year\": year_val,\n",
    "                                        \"quarter\": quarter,\n",
    "                                        \"dataset\": category\n",
    "                                    })\n",
    "                            # Districts\n",
    "                            for d in districts_list:\n",
    "                                if \"metric\" in d:\n",
    "                                    all_rows.append({\n",
    "                                        \"level\": \"district\",\n",
    "                                        \"entity\": d.get(\"entityName\"),\n",
    "                                        \"type\": d[\"metric\"].get(\"type\"),\n",
    "                                        \"count\": d[\"metric\"].get(\"count\"),\n",
    "                                        \"amount\": d[\"metric\"].get(\"amount\"),\n",
    "                                        \"year\": year_val,\n",
    "                                        \"quarter\": quarter,\n",
    "                                        \"dataset\": category\n",
    "                                    })\n",
    "                                else:\n",
    "                                    all_rows.append({\n",
    "                                        \"level\": \"district\",\n",
    "                                        \"entity\": d.get(\"name\"),\n",
    "                                        \"registeredUsers\": d.get(\"registeredUsers\"),\n",
    "                                        \"year\": year_val,\n",
    "                                        \"quarter\": quarter,\n",
    "                                        \"dataset\": category\n",
    "                                    })\n",
    "                            # Pincodes\n",
    "                            for p in pincodes_list:\n",
    "                                if \"metric\" in p:\n",
    "                                    all_rows.append({\n",
    "                                        \"level\": \"pincode\",\n",
    "                                        \"entity\": p.get(\"entityName\"),\n",
    "                                        \"type\": p[\"metric\"].get(\"type\"),\n",
    "                                        \"count\": p[\"metric\"].get(\"count\"),\n",
    "                                        \"amount\": p[\"metric\"].get(\"amount\"),\n",
    "                                        \"year\": year_val,\n",
    "                                        \"quarter\": quarter,\n",
    "                                        \"dataset\": category\n",
    "                                    })\n",
    "                                else:\n",
    "                                    all_rows.append({\n",
    "                                        \"level\": \"pincode\",\n",
    "                                        \"entity\": p.get(\"name\"),\n",
    "                                        \"registeredUsers\": p.get(\"registeredUsers\"),\n",
    "                                        \"year\": year_val,\n",
    "                                        \"quarter\": quarter,\n",
    "                                        \"dataset\": category\n",
    "                                    })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    output_csv = os.path.join(output_folder, f\"{category}_data.csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\" CSV created for {category} at: {output_csv}, total rows: {len(df)}\")\n",
    "\n",
    "# Top categories\n",
    "top_categories = [\"transaction\", \"user\", \"insurance\"]\n",
    "for cat in top_categories:\n",
    "    process_top_json(cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fea2d9-f504-4963-805e-85fa5090f5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e1bb5-1cae-4de2-aa60-22e04d353f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
